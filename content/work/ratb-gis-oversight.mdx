---
title: "Recovery oversight with GIS: targeting risk and misrepresentation"
slug: "ratb-gis-oversight"
client: "U.S. Government (RATB)"
timeframe: "2011–2012"
role: "Data analyst (GIS lead)"
stack:
  - ESRI
  - Palantir
  - GIS
  - Data ontology
tags:
  - GIS
  - Accountability
  - Public sector
  - Palantir
  - Investigations
featured: false
image: "/images/projects/recovery-oversight.png"
executiveSummary: "Led GIS integration of government data for Recovery Act oversight. Used Palantir for network analysis. Conceived an investigation that identified 90 contract misrepresentations."
builderSummary: "Geospatial datasets and investigative workflows in ESRI and Palantir. Built the data ontology for cross-system analysis. Conceived the investigation that uncovered widespread misrepresentation."
---

## Context

The **Recovery Accountability and Transparency Board (RATB)** was a federal entity charged with overseeing the $840 billion American Recovery and Reinvestment Act. Its mission: prevent fraud, waste, and abuse in Recovery Act spending.

I joined as a data analyst with a GIS specialization. The question was straightforward: how do you identify where risk is concentrated across thousands of funded projects spread across the country?

## How GIS changed the investigation workflow

Before geospatial analysis, investigators relied primarily on tips, audits, and financial anomaly detection. Adding a spatial dimension opened new lines of inquiry.

Geographic clustering of anomalies was the first. Mapping expenditure patterns revealed regions where spending didn't match expected activity — concentrations that weren't visible in tabular data. Cross-referencing location data came next. Overlaying recipient addresses, project sites, and subcontractor locations helped identify potential misrepresentation — projects claiming activity in locations with no evidence of work. And maps made complex investigative findings accessible to audiences ranging from federal investigators to congressional staff to international delegations.

## Leading GIS integration

I led the integration of geospatial data across multiple government systems, building the spatial infrastructure that made location-based investigation possible. That meant standardizing disparate address formats, geocoding recipient and contractor records, and creating overlay datasets linking financial flows to physical locations across the country.

## Network analysis with Palantir

I used **Palantir** for network and lead analysis — tracing entity relationships across financial and organizational datasets to surface connections that weren't visible in any single data source. That involved mapping relationships between contractors, subcontractors, and recipients to identify suspicious patterns of coordination or misrepresentation.

## The data ontology

I assisted in creating a **data ontology** that structured how entities (contractors, awards, locations, transactions) were classified and related across the Board's analytical systems. This shared framework made it possible to connect GIS findings with Palantir link analysis, creating a unified investigative picture from previously siloed datasets.

## The investigation that uncovered 90 misrepresentations

I conceived and led an investigation that combined geospatial analysis with network intelligence to **identify 90 contract misrepresentations** — cases where contractors made false claims about project locations, capabilities, or compliance. By layering spatial anomalies over entity relationship patterns, I surfaced a systematic pattern that manual review alone had missed.

This was the kind of insight that only emerges when you combine multiple analytical disciplines. Geography reveals where the anomalies are. Network analysis reveals who is connected. A structured ontology connects the dots.

## Presenting to different audiences

Internal investigators needed detailed spatial evidence they could act on. Government leadership needed summary views showing portfolio-level risk. International delegations visited to understand how the U.S. was handling Recovery Act oversight, and those presentations had to be accessible without exposing sensitive details.

This is where I first learned that analytics is only as useful as the decisions it informs — and that requires meeting each audience where they are.

## What I took forward

This was my first role working with data at mission-critical stakes, and the lessons have stayed with me. Data quality is non-negotiable when your analysis supports investigations. Visualization isn't decoration — it's how you make complex patterns intelligible. And the best investigations are conceived, not stumbled into. The 90-misrepresentation finding came from deliberately designing an analytical approach, not from waiting for a tip.
